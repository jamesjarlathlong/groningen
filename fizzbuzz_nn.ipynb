{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import tile_creater\n",
    "tile_creater.discretiser(0.1,0.2,(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_encode(i, num_digits):\n",
    "    return np.array([i >> d & 1 for d in range(num_digits)])\n",
    "def fizz_buzz_encode(i):\n",
    "    if   i % 15 == 0: return 0#np.array([0, 0, 0, 1])\n",
    "    elif i % 5  == 0: return 1 #np.array([0, 0, 1, 0])\n",
    "    elif i % 3  == 0: return 2#np.array([0, 1, 0, 0])\n",
    "    else:             return 3#np.array([1, 0, 0, 0])\n",
    "\n",
    "def invert(label, sample):\n",
    "    if label == 3:\n",
    "        return sample\n",
    "    else:\n",
    "        return {0:'fizzbuzz', 1:'fizz',2:'buzz'}[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_training(num_digits, therange):\n",
    "    for i in range(*therange):\n",
    "        yield binary_encode(i, num_digits)\n",
    "names=[str(i) for i in range(10)]\n",
    "train_x = pd.DataFrame((i for i in generate_training(10,(101,1024))), columns=names)\n",
    "test_range = (0,100)\n",
    "train_range = (101,1024)\n",
    "train_y = np.asarray([fizz_buzz_encode(i) for i in range(*train_range)])\n",
    "test_x = pd.DataFrame((i for i in generate_training(10,test_range)),columns=names)\n",
    "test_y = np.asarray([fizz_buzz_encode(i) for i in range(*test_range)])\n",
    "\n",
    "def train_input_fn(features, labels, batch_size=20):\n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))#.map(namer)\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.shuffle(1000).repeat(100).batch(batch_size)\n",
    "    # Return the dataset.\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    data, labels = iterator.get_next()\n",
    "    return data, labels\n",
    "def test_input_fn(features, labels, batch_size=20):\n",
    "    \"\"\"An input function for evaluation or prediction\"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))#.map(namer)\n",
    "    # Batch the examples\n",
    "    assert batch_size is not None, \"batch_size must not be None\"\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    # Return the dataset.\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    data, labels = iterator.get_next()\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(train_x, train_y, test_x, test_y):\n",
    "    my_feature_columns = [tf.feature_column.numeric_column(key=str(k))\n",
    "                          for k in range(10)]\n",
    "\n",
    "    # Build 2 hidden layer DNN with 10, 10 units respectively.\n",
    "    classifier = tf.estimator.DNNClassifier(\n",
    "        feature_columns=my_feature_columns,\n",
    "        # The model must choose between 4 classes\n",
    "        n_classes=4,\n",
    "        # Two hidden layers of 100 nodes each.\n",
    "        hidden_units=[100, 100]\n",
    "        )\n",
    "\n",
    "    # Train the Model.\n",
    "    classifier.train(input_fn=lambda:train_input_fn(train_x, train_y))\n",
    "\n",
    "    # Evaluate the model.\n",
    "    eval_result = classifier.evaluate(\n",
    "        input_fn=lambda:test_input_fn(test_x, test_y))\n",
    "\n",
    "    print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n",
    "    predictions = classifier.predict(\n",
    "        input_fn=lambda:test_input_fn(test_x,test_y))\n",
    "    formatted = [invert(pred.get('class_ids')[0], idx)\n",
    "                for idx, pred in enumerate(predictions)]\n",
    "    expected = [invert(fizz_buzz_encode(i),i) for i, p in enumerate(test_y)]\n",
    "    return expected, formatted\n",
    "e, f = main(train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for expected, got in zip(e,f):\n",
    "    print('answer is {}, neural net predicted {} {}'.format(expected, got, ('wrong' if expected!=got else '')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "groningen",
   "language": "python",
   "name": "groningen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
